#Random Forest 
library(randomForest)
# Splitting the data into the Training set and Test set
set.seed(277)
ind<- sample(2, nrow(mydata),replace=TRUE, prob =c(0.7, 0.3))
train<- mydata [ind==1,]
test<- mydata [ind==2, ]    
# Setup for cross validation
train.control<- trainControl(method= "cv", number = 10)
tuneGrid= expand.grid(mtry= c(1:10))
# Train the model
modelcv<- train(Y ~. , data= train, method= "rf", ntree = 500, tuneGrid = tuneGrid, metric= "Accuracy", trControl = train.control)
print(modelcv)
plot(modelcv, cex=1.3, col='black',
     cex.main=3.3, cex.sub=4.3,
     cex.lab=3.3, cex.axis=6.3,
     font.main=4.0,
     font.sub=4.3,
     font.axis=4.3,
     main="Full RF")

# Summarize the results
# Predicting the results 
ps2<- predict(modelcv, test, type="prob") [,2]
predictionclass2 = ifelse(ps2 > 0.5, 1, 0)
# confusion Matrix
confusionMatrix(as.factor(predictionclass2), as.factor(test$Y),mode="everything", positive = '1')
# Area under the curve (AUC)
prs2<- ROCR::prediction(ps2, test$Y)
auc2<- performance(prs2, measure = "auc")
auc2<-unlist(slot(auc2, "y.values"))
auc2<- round(auc2,4)
auc2
# ROC Plot for RF
rocrf<- performance(prs2, "tpr", "fpr")
plot(rocrf,
     colorize=T, cex=4.3, col='black',
     cex.main=1.3, cex.sub=4.3,
     cex.lab=1.3, cex.axis=4.3,
     font.main=4.3,
     font.sub=4.3,
     font.axis=4.3,
     main="ROC Curve of full RF",
     ylab="Sensitivity",
     xlab=" 1-Specificity")
abline (a=0, b=1)
legend(0.8,.2, auc2, title="AUC", cex= 1.0)                                 

#Variables Imp based on best mtry
RF<- randomForest(Y ~ . , data = train, ntree = 500, mtry=4)
xx<- varImpPlot(RF)

# Reduced RF
str(mydata)
mydata4<- mydata[, c(1,3,5,7,13,17,18,19,20)]
str(mydata4)
# Splitting the data into the Training set and Test set
set.seed(512)
ind<- sample(2, nrow(mydata4),replace=TRUE, prob =c(0.7, 0.3))
train4<- mydata4[ind==1,]
test4<- mydata4[ind==2,]
# Setup for cross validation
train.control<- trainControl(method= "cv", number = 10)
tuneGrid= expand.grid(mtry= c(1:10))
# Train the model
modell.rf<- train(Y ~ . , data= train4, method= "rf", ntree = 500, tuneGrid = tuneGrid, metric = "Accuracy", trControl = train.control)
print(modell.rf)
plot(modell.rf, cex=1.3, col='black',
     cex.main=1.3, cex.sub=4.3,
     cex.lab=1.3, cex.axis=4.3,
     font.main=4.0,
     font.sub=4.3,
     font.axis=4.3,
     main="Reduced RF")
# Predicting the results 
prfr<- predict(modell.rf, test4, type="prob")[,2]
predictionclassrr = ifelse(prfr > 0.5, 1, 0)
# confusion Matrix
confusionMatrix(as.factor(predictionclassrr), as.factor(test4$Y), mode = "everything", positive = '1')
# Area under Curve (AUC)
prfsr<- ROCR::prediction(prfr, test4$Y)
aucrr<- performance(prfsr, "auc")
aucrr<- unlist(slot(aucrr, "y.values"))
aucrr<- round(aucrr, 4)
aucrr
#Plot ROC for Reduced RF
rocrrf<- performance(prfsr, "tpr", "fpr")
plot(rocrrf,
     colorize=T, cex=4.3, col='black',
     cex.main=1.3, cex.sub=4.3,
     cex.lab=1.3, cex.axis=4.3,
     font.main=4.3,
     font.sub=4.3,
     font.axis=4.3,
     main="ROC Curve of reduced RF",
     ylab="Sensitivity",
     xlab="1-Specificity")
abline (a=0, b=1)
legend(.8, .2, aucrr, title="AUC", cex= 1.0)
#####

